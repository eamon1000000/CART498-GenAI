{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_L_3Y81gRTr",
        "outputId": "63d790fa-d5c4-4d14-efbd-ec728f407279"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Define the input phrase\n",
        "full_prompt = '''One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.'''\n",
        "\n",
        "def apply_p_plus_n(text, n=7):\n",
        "\n",
        "    lines = text.strip().split('\\n') #split by line\n",
        "    new_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        if not line.strip():  # Skip empty lines\n",
        "            new_lines.append(line)\n",
        "            continue\n",
        "\n",
        "        # Split line into words\n",
        "        words = line.split()\n",
        "\n",
        "        if len(words) == 0:  # Skip if no words\n",
        "            new_lines.append(line)\n",
        "            continue\n",
        "\n",
        "        # Remove the last word to create the prompt ready to apply prediction algorithm to\n",
        "        prompt_words = words[:-1]\n",
        "        prompt = ' '.join(prompt_words)\n",
        "\n",
        "        # Tokenize the prompt\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "        # Get model predictions\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        # Get logits for the last token\n",
        "        last_token_logits = logits[0, -1, :]\n",
        "\n",
        "        # Convert to probabilities\n",
        "        probabilities = torch.softmax(last_token_logits, dim=-1)\n",
        "\n",
        "        # Get top k tokens (we need at least n tokens)\n",
        "        top_k_probabilities, top_k_indices = torch.topk(probabilities, n)\n",
        "\n",
        "        # Get the nth most probable token (index n-1 since 0-indexed)\n",
        "        nth_token_idx = top_k_indices[n-1]\n",
        "        nth_token = tokenizer.decode(nth_token_idx).strip()\n",
        "\n",
        "        # Construct new line with truncated line of original prompt + new nth most likely word\n",
        "        new_line = prompt + ' ' + nth_token\n",
        "        new_lines.append(new_line) #append to new poem\n",
        "\n",
        "    return '\\n'.join(new_lines)\n",
        "\n",
        "\n",
        "# apply this logic for n=7 (p+7)\n",
        "p7_text = apply_p_plus_n(full_prompt, n=7)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL P+7 OUTPUT\")\n",
        "print(\"=\" * 60)\n",
        "print(p7_text)\n",
        "\n",
        "# Save to file\n",
        "with open('P+7.txt', 'w') as f:\n",
        "    f.write(p7_text)\n",
        "\n",
        "\n",
        "# Example n=699 (P+699)\n",
        "p699_text = apply_p_plus_n(full_prompt, n=699)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL P+699 OUTPUT\")\n",
        "print(\"=\" * 60)\n",
        "print(p699_text)\n",
        "\n",
        "# Save to file\n",
        "with open('P+699.txt', 'w') as f:\n",
        "    f.write(p699_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
